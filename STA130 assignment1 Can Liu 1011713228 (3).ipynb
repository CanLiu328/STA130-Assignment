{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753988fc",
   "metadata": {},
   "source": [
    "#### 1. Pick one of the datasets from the ChatBot session(s) of the **TUT demo** (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bbec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to just use the following if you prefer...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff0fb6",
   "metadata": {},
   "source": [
    "#### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has, and then\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2203d3",
   "metadata": {},
   "source": [
    "1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,  \n",
    "2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce727607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4063e",
   "metadata": {},
   "source": [
    "The concept of \"observation\" represents typically to the number of rows in the dataset.Conversely, \"variable\" often refers to the number of columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e91064",
   "metadata": {},
   "source": [
    "#### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5144e73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8d7d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birthday\n",
       "1-27     2\n",
       "12-5     2\n",
       "7-31     2\n",
       "3-26     2\n",
       "8-3      2\n",
       "        ..\n",
       "4-3      1\n",
       "10-26    1\n",
       "7-23     1\n",
       "12-8     1\n",
       "3-8      1\n",
       "Name: count, Length: 361, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['birthday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bd636",
   "metadata": {},
   "source": [
    "Because when I print df.describe(), it only provided me with the number of rows.Hence, for the diversity of data,I print the other df['column'] above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da403ec",
   "metadata": {},
   "source": [
    "#### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7447a90d",
   "metadata": {},
   "source": [
    "For df.shape,it would provide you with all values including some missing values and does not subject to null values or data type.Conversely,for df.describe, count represents the numbers of missing values,it does not include null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d4a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (5, 3)\n",
      "\n",
      "Summary statistics:\n",
      "             Age        Salary\n",
      "count   4.000000      4.000000\n",
      "mean   32.500000  58750.000000\n",
      "std     6.454972   8539.125638\n",
      "min    25.000000  50000.000000\n",
      "25%    28.750000  53750.000000\n",
      "50%    32.500000  57500.000000\n",
      "75%    36.250000  62500.000000\n",
      "max    40.000000  70000.000000\n",
      "\n",
      "Non-null count for each column:\n",
      "Name      5\n",
      "Age       4\n",
      "Salary    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Name': ['Alice', 'Bob', 'Carol', 'Dave', 'Eve'],\n",
    "        'Age': [25, 30, None, 35, 40],\n",
    "        'Salary': [50000, 55000, 60000, None, 70000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Shape of the dataframe (total rows and columns)\n",
    "print(f\"Shape of the dataframe: {df.shape}\")\n",
    "\n",
    "# Describe the dataset\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Count of non-null values\n",
    "print(\"\\nNon-null count for each column:\")\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7356cb1",
   "metadata": {},
   "source": [
    "#### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9727182",
   "metadata": {},
   "source": [
    "For attribute,it tends to provide you access to data or metadata about the object and need not add parenthses,for example:df.shape or df.columns.For method, it always performs an action or computation on the object and often require a parentheses after it, for example:df.describe() or df.head()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69779cc3",
   "metadata": {},
   "source": [
    "#### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6fc26",
   "metadata": {},
   "source": [
    "Count: The number of non-null (non-missing) values in the column.\n",
    "Mean: The average value of the column.\n",
    "Standard Deviation (std): A measure of how spread out the values are around the mean.\n",
    "Min: The smallest value in the column.\n",
    "25% (1st quartile): The value below which 25% of the data falls (first quartile).\n",
    "50% (median): The value below which 50% of the data falls (second quartile or median).\n",
    "75% (3rd quartile): The value below which 75% of the data falls (third quartile).\n",
    "Max: The largest value in the column.\n",
    "df.describe() provides summary statistics for each numerical column, ignoring null values.If there are missing values, the \"count\" will be less than the total number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea553f",
   "metadata": {},
   "source": [
    "#### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c3051",
   "metadata": {},
   "source": [
    "1. Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb50a0c",
   "metadata": {},
   "source": [
    "For,df.dropna Used when you want to remove rows (or columns) containing null values while preserving the rest of the data in the DataFrame.For del df['col'],Used when you want to permanently remove a column, regardless of whether it contains missing values or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521ed71f",
   "metadata": {},
   "source": [
    "Scenario: Data Cleaning for Missing Entries\n",
    "Imagine you have a dataset of customer information for a store, including the customer's name, age, email, and purchase amount. Some rows are missing values for the \"email\" or \"purchase_amount\" columns. You want to remove only the rows where important data (like the \"purchase_amount\") is missing, while preserving the other columns, including \"email\", because missing emails might not be crucial for some analyses.\n",
    "\n",
    "In this case, using df.dropna() would be preferred over del df['col'] because you want to keep the \"email\" column and the rest of the data while cleaning out rows with incomplete purchase information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6254621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after using df.dropna():\n",
      "    name   age              email  purchase_amount\n",
      "0  Alice  25.0  alice@example.com            100.0\n",
      "1    Bob  30.0    bob@example.com            200.0\n",
      "3   Dave  40.0   dave@example.com            150.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with missing values\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Carol', 'Dave'],\n",
    "    'age': [25, 30, None, 40],\n",
    "    'email': ['alice@example.com', 'bob@example.com', None, 'dave@example.com'],\n",
    "    'purchase_amount': [100, 200, None, 150]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use df.dropna() to remove rows where 'purchase_amount' is missing\n",
    "df_cleaned = df.dropna(subset=['purchase_amount'])\n",
    "\n",
    "print(\"DataFrame after using df.dropna():\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cc7f3",
   "metadata": {},
   "source": [
    "2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()` <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2779e1d",
   "metadata": {},
   "source": [
    "Scenario: Dropping an Unnecessary Column\n",
    "Suppose you have a DataFrame of customer purchase data, including a column called middle_name. The middle_name column contains many NaN values, but even for the non-missing entries, it's not useful for your current analysis of purchase behavior. In this case, you don't want to handle the missing values with df.dropna(), because the entire middle_name column is irrelevant. You just want to remove the column altogether to declutter the dataset.\n",
    "\n",
    "In this situation, using del df['middle_name'] would be preferred over df.dropna(), because you want to completely remove the column rather than dealing with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf82e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after using del df['middle_name']:\n",
      "  first_name last_name  purchase_amount\n",
      "0      Alice     Smith              100\n",
      "1        Bob     Jones              200\n",
      "2      Carol     Brown              150\n",
      "3       Dave     Davis              175\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with an irrelevant column ('middle_name') and some missing values\n",
    "data = {\n",
    "    'first_name': ['Alice', 'Bob', 'Carol', 'Dave'],\n",
    "    'middle_name': [None, 'Andrew', None, None],\n",
    "    'last_name': ['Smith', 'Jones', 'Brown', 'Davis'],\n",
    "    'purchase_amount': [100, 200, 150, 175]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use del df['middle_name'] to remove the entire column\n",
    "del df['middle_name']\n",
    "\n",
    "print(\"DataFrame after using del df['middle_name']:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c48b85",
   "metadata": {},
   "source": [
    "3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e1bea",
   "metadata": {},
   "source": [
    "1.Irrelevant Columns with Missing Values Won't Affect Row Removal:\n",
    "Scenario: If you apply df.dropna() first, missing values in columns that you later intend to delete might cause rows to be dropped unnecessarily.\n",
    "Problem: If you have a column with NaN values that is irrelevant to your analysis, and you apply df.dropna() first, the presence of those missing values could cause rows to be removed that you may otherwise want to keep.\n",
    "Solution: By using del df['col'] first, you ensure that irrelevant columns with missing values do not influence the removal of rows based on other important columns.Prevents Accidental Data Loss:\n",
    "If you run df.dropna() before deleting columns, you might inadvertently delete rows due to missing values in columns that are not relevant to your analysis.\n",
    "For example, if the column to be deleted contains many NaN values, dropping rows based on these NaN entries could result in more data loss than intended.\n",
    "3. Keeps the Dataset Focused on Important Columns:\n",
    "By deleting the irrelevant column first, you're ensuring that the dataset is focused on the variables that are important to your analysis. This makes the logic of df.dropna() more meaningful because it will only drop rows based on columns that matter.\n",
    "This helps when working with large datasets where many columns may not be important and could introduce unnecessary complexity when cleaning up missing data.\n",
    "4. Improved Performance:\n",
    "Deleting irrelevant columns before running df.dropna() can improve the performance of the operation, especially in large datasets.\n",
    "Why? df.dropna() has to check each row and column for missing values, so if you first remove unnecessary columns, there are fewer values for the method to process.\n",
    "Summary:\n",
    "Using del df['col'] before df.dropna() is important because:\n",
    "It prevents unnecessary row removal due to missing values in irrelevant columns.\n",
    "It avoids accidental data loss by ensuring only relevant columns are considered when handling missing data.\n",
    "It keeps the dataset focused on important columns, leading to more meaningful data cleaning.\n",
    "It can improve performance by reducing the number of columns df.dropna() has to process.\n",
    "This order ensures you’re cleaning the dataset more effectively and efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b034a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after using df.dropna() first:\n",
      "  first_name middle_name last_name  purchase_amount\n",
      "1        Bob      Andrew     Jones            200.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame with an irrelevant column ('middle_name') that has missing values\n",
    "data = {\n",
    "    'first_name': ['Alice', 'Bob', 'Carol', 'Dave'],\n",
    "    'middle_name': [None, 'Andrew', None, None],\n",
    "    'last_name': ['Smith', 'Jones', 'Brown', 'Davis'],\n",
    "    'purchase_amount': [100, 200, None, 150]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# If you apply df.dropna() first, rows with missing 'middle_name' will be dropped unnecessarily\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"DataFrame after using df.dropna() first:\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47121d37",
   "metadata": {},
   "source": [
    "4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3883363",
   "metadata": {},
   "source": [
    "It is not hard for us to figure out which one column exists most of the missing values,so this time we only need to use del df['col'] to delete that column first.Conversely, if we try to use df. dropna first,beacuse the data is dispersive,we tend to delete many rouws leding to lack of the integrality of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bda4eb",
   "metadata": {},
   "source": [
    "#### 8. Give brief explanations in your own words for any requested answers to the questions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8278a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a215f525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>purchase_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>None</td>\n",
       "      <td>Smith</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Jones</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carol</td>\n",
       "      <td>None</td>\n",
       "      <td>Brown</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dave</td>\n",
       "      <td>None</td>\n",
       "      <td>Davis</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name middle_name last_name  purchase_amount\n",
       "0      Alice        None     Smith            100.0\n",
       "1        Bob      Andrew     Jones            200.0\n",
       "2      Carol        None     Brown              NaN\n",
       "3       Dave        None     Davis            150.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bb0c0",
   "metadata": {},
   "source": [
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161d555",
   "metadata": {},
   "source": [
    "Count reflects the total number of non-null values in each column.\n",
    "It is independent of other columns.\n",
    "It does not take any groupings or categories into account.\n",
    "Useful for getting a high-level overview of missing data in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e79a4",
   "metadata": {},
   "source": [
    "3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717733b",
   "metadata": {},
   "source": [
    "1.Forget to include `import pandas as pd` in your code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60aa4d50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dead366",
   "metadata": {},
   "source": [
    "The pd alias is commonly used for the pandas library, but it must be explicitly defined using the import statement. Without this import, Python doesn't recognize pd.\n",
    "Solution:\n",
    "You need to import the pandas library at the beginning of your script. Here’s how to fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468abedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age\n",
       "count  5.000000\n",
       "mean   4.000000\n",
       "std    1.581139\n",
       "min    2.000000\n",
       "25%    3.000000\n",
       "50%    4.000000\n",
       "75%    5.000000\n",
       "max    6.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Then, you can use pd to reference the pandas library\n",
    "data = {\n",
    "    'species': ['cat', 'dog', 'dog', 'bird', 'cat', 'dog', 'bird'],\n",
    "    'age': [3, 5, None, 2, 4, None, 6],\n",
    "    'personality': ['lazy', 'active', None, 'lazy', 'active', None, 'active']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Now you can use the pandas library (pd) without any errors\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Mistype \"titanic.csv\" as \"titanics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b7d8ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mtitanics\u001b[49m\u001b[38;5;241m.\u001b[39mcsv)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group by 'class' and describe 'age' for each group\u001b[39;00m\n\u001b[1;32m      8\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'titanics' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(titanics.csv)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efb217",
   "metadata": {},
   "source": [
    "Possible Causes of the Error:\n",
    "Typo or Misspelling: You might have intended to use a variable name like titanic or df but accidentally typed titanics.\n",
    "Object Not Initialized: The titanics variable may refer to a dataset or DataFrame that hasn't been loaded or initialized properly.\n",
    "Solutions:\n",
    "1. Check for Typos:\n",
    "If titanics was supposed to be something like titanic, double-check for any typographical errors in your code.Solutions:\n",
    "Double-check the variable name for typos.\n",
    "Ensure the dataset or object has been loaded or initialized properly before using it.\n",
    "If using a common dataset like Titanic, make sure it is loaded using the appropriate method, such as loading a CSV file or using a library like seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0718c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Now you can work with the Titanic dataset\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254d44",
   "metadata": {},
   "source": [
    "3. Try to use a dataframe before it's been assigned into the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da2a350",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group by 'class' and describe 'age' for each group\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = DF.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc9d81",
   "metadata": {},
   "source": [
    "Make sure that you consistently use df (all lowercase) throughout your code. If you mistakenly use DF or another variable name that isn't defined, it will cause the error.\n",
    "Ensure that you're using the correct variable name (df), not DF. If you're following my previous example, here's how the code should look:\n",
    "The error you're encountering (NameError: name 'DF' is not defined) indicates that Python is looking for a variable named DF, but it hasn't been defined. In Python, variable names are case-sensitive, so if you named your DataFrame as df but use DF elsewhere, it will raise an error.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdb1c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)  # Make sure it's 'df', not 'DF'\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60dc31",
   "metadata": {},
   "source": [
    "4. Forget one of the parentheses somewhere the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1607ee41",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (4212528697.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"class\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847fc39",
   "metadata": {},
   "source": [
    "Instructions to Solve the Error:\n",
    "Go through your code and look for places where you've used ( and ensure that there is a matching ) at the end.\n",
    "Check other similar symbols like {} or [], as they should also be balanced.\n",
    "You can use your code editor's \"highlight matching parentheses\" feature to find unmatched parentheses easily.\n",
    "If the error persists and you share your current code, I can help pinpoint the exact issue.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e087b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of balanced parentheses\n"
     ]
    }
   ],
   "source": [
    "print(\"This is an example of balanced parentheses\")  # Both opening and closing parentheses are present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9307ef",
   "metadata": {},
   "source": [
    "5. Mistype one of the names of the chained functions with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a13684f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group by 'class' and describe 'age' for each group\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescrible\u001b[49m()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1312\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1314\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"class\")[\"age\"].describle()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5e810",
   "metadata": {},
   "source": [
    "The error AttributeError: 'SeriesGroupBy' object has no attribute 'describle' occurs because you are calling a non-existent method describle (which is likely a typo). The correct method is describe().\n",
    "\n",
    "Cause:\n",
    "Typo: The method should be describe(), not describle(). Python is case-sensitive, and a small typo like this can lead to an error.\n",
    "Solution:\n",
    "Replace describle() with describe() in your code.Ensure that you use the correct spelling of the method describe(), which is used to generate summary statistics for each group in a DataFrame or Series.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72847316",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df.groupby(\"class\")[\"age\"].describe()  # Correct spelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34cc480",
   "metadata": {},
   "source": [
    "6. Use a column name that's not in your data for the `groupby` and column selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56df99b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Group by 'class' and describe 'age' for each group\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Class'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(\"Class\")[\"Age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35bef8e",
   "metadata": {},
   "source": [
    "The KeyError: 'Class' error occurs when you're trying to reference a column name ('Class' in this case) that does not exist in the DataFrame. This can happen due to:\n",
    "\n",
    "Incorrect column name: The column may not be named 'Class'. Python is case-sensitive, so 'Class' and 'class' are different.\n",
    "Whitespace or extra characters: Sometimes column names contain leading/trailing spaces, which may cause a mismatch.\n",
    "Non-existent column: The column you are referring to might not exist in the DataFrame.\n",
    "Steps to Fix the Error:\n",
    "Check the column names: Print out the column names to ensure you're using the correct one.\n",
    "print(df.columns)\n",
    "This will show you the exact names of the columns.\n",
    "\n",
    "Ensure proper capitalization: If the actual column is named 'class' (all lowercase), update the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c894b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "class                                                            \n",
       "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"class\")[\"age\"].describe()  # Correct column name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399f863",
   "metadata": {},
   "source": [
    " 7. Forget to put the column name as a string in quotes for the `groupby` and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760b62df",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2473096018.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    grouped_data = df.groupby(class)[age].describe()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age' for each group\n",
    "grouped_data = df.groupby(class)[age].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5f461",
   "metadata": {},
   "source": [
    "A Syntax Error: invalid syntax occurs in Python when the interpreter encounters a line of code that doesn't follow the proper syntax rules of the language. This error is common when something is incorrectly written or missing in the code.Missing colons (:) after control structures:\n",
    "\n",
    "python\n",
    "How to Solve the Issue:\n",
    "Carefully read the error message: It will tell you which line the error is on.\n",
    "Look for common mistakes: As listed above, check for missing parentheses, colons, improper indentation, or unbalanced quotes.\n",
    "Use a code editor: Most editors will highlight syntax errors for you, making them easier to spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83165a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://chatgpt.com/share/cd66661c-b66e-417f-bd61-bf7596b96adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0830513",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://chatgpt.com/share/3429fa28-a3be-4abc-84b4-b4b739765553"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
